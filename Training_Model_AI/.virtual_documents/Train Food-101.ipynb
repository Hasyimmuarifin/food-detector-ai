


pip install tensorflow numpy matplotlib





import os
import tensorflow as tf

DATASET_DIR = "food-101"
IMAGES_DIR = os.path.join(DATASET_DIR, "images")
META_DIR = os.path.join(DATASET_DIR, "meta")

# Load daftar kelas
with open(os.path.join(META_DIR, "classes.txt")) as f:
    class_names = [line.strip() for line in f.readlines()]
class_to_index = {name: idx for idx, name in enumerate(class_names)}

# Load daftar gambar untuk training dan testing
def load_split(split):
    with open(os.path.join(META_DIR, f"{split}.txt")) as f:
        lines = [line.strip() for line in f.readlines()]
    image_paths = [os.path.join(IMAGES_DIR, f"{line}.jpg") for line in lines]
    labels = [class_to_index[line.split("/")[0]] for line in lines]
    return image_paths, labels

train_paths, train_labels = load_split("train")
test_paths, test_labels = load_split("test")





IMG_SIZE = 224
BATCH_SIZE = 32
AUTOTUNE = tf.data.AUTOTUNE

def preprocess(path, label):
    image = tf.io.read_file(path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
    image = image / 255.0
    return image, tf.one_hot(label, depth=len(class_names))

train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))
train_ds = train_ds.map(preprocess, num_parallel_calls=AUTOTUNE)
train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)

test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))
test_ds = test_ds.map(preprocess, num_parallel_calls=AUTOTUNE)
test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)





base_model = tf.keras.applications.MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False

x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
output = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)

model = tf.keras.models.Model(inputs=base_model.input, outputs=output)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(train_ds, epochs=50, validation_data=test_ds)














from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns





# Ambil semua gambar dan label dari test_ds
y_true = []
y_pred = []

for images, labels in test_ds:
    preds = model.predict(images)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(np.argmax(labels.numpy(), axis=1))








cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(15, 12))
sns.heatmap(cm, xticklabels=class_names, yticklabels=class_names, 
            annot=False, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()





report = classification_report(y_true, y_pred, target_names=class_names)
print(report)





with open("evaluation_report.txt", "w") as f:
    f.write(report)





plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()





model.save("food101_model.h5")





converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open("food101_model.tflite", "wb") as f:
    f.write(tflite_model)





with open("labels.txt", "w") as f:
    for label in class_names:
        f.write(label + "\n")
